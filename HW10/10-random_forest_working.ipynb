{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fearon & Laitin Replication\n",
    "\n",
    "Today, we're going to see if we can do a better job than Fearon & Laitin do in predicting the onset of civil wars. You may use any method you like, but I will get you started using their method (logistic regression) and also random forests.\n",
    "\n",
    "To evaluate how well we do, we will use out-of-sample testing. I will help you divide the data into 3 sets: Training, Validation, and Testing. You should fit a model on the training data _only_ and evaluate how well it performs out-of-sample on the _validation_ data. Only once you have selected a _final_ model should you evaluate it's performance on the _test_ set. Once you've \"peeked\" at the test set, you should no longer continue to alter your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ccode</th>\n",
       "      <th>country</th>\n",
       "      <th>cname</th>\n",
       "      <th>cmark</th>\n",
       "      <th>year</th>\n",
       "      <th>wars</th>\n",
       "      <th>war</th>\n",
       "      <th>warl</th>\n",
       "      <th>onset</th>\n",
       "      <th>...</th>\n",
       "      <th>empolity2l</th>\n",
       "      <th>sdwars</th>\n",
       "      <th>sdonset</th>\n",
       "      <th>colwars</th>\n",
       "      <th>colonset</th>\n",
       "      <th>cowwars</th>\n",
       "      <th>cowonset</th>\n",
       "      <th>cowwarl</th>\n",
       "      <th>sdwarl</th>\n",
       "      <th>colwarl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.68712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ccode country cname  cmark  year  wars  war  warl  onset  ...  \\\n",
       "0           1      2     USA   USA      1  1945     0    0     0      0  ...   \n",
       "1           2      2     USA   USA      0  1946     0    0     0      0  ...   \n",
       "2           3      2     USA   USA      0  1947     0    0     0      0  ...   \n",
       "3           4      2     USA   USA      0  1948     0    0     0      0  ...   \n",
       "4           5      2     USA   USA      0  1949     0    0     0      0  ...   \n",
       "\n",
       "   empolity2l  sdwars  sdonset colwars  colonset  cowwars cowonset  cowwarl  \\\n",
       "0     7.68712       0        0     NaN       NaN      0.0      0.0      0.0   \n",
       "1    10.00000       0        0     NaN       NaN      0.0      0.0      0.0   \n",
       "2    10.00000       0        0     NaN       NaN      0.0      0.0      0.0   \n",
       "3    10.00000       0        0     NaN       NaN      0.0      0.0      0.0   \n",
       "4    10.00000       0        0     NaN       NaN      0.0      0.0      0.0   \n",
       "\n",
       "   sdwarl  colwarl  \n",
       "0       0      NaN  \n",
       "1       0      NaN  \n",
       "2       0      NaN  \n",
       "3       0      NaN  \n",
       "4       0      NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"FearonLaitin.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Scikit learn likes to fit models to data in the form of two numpy arrays or pandas matrices. The first one, `X`, is a matrix of all your predictor variables (also known as independent variables). The second one, `y`, is the column vector of your dependent variables. If `X` is $(n \\times k)$ dimensions, `y` is $(n \\times 1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6191 entries, 0 to 6608\n",
      "Data columns (total 12 columns):\n",
      "onset       6191 non-null int64\n",
      "warl        6191 non-null int64\n",
      "gdpenl      6191 non-null float64\n",
      "lpop        6191 non-null float64\n",
      "lmtnest     6191 non-null float64\n",
      "ncontig     6191 non-null int64\n",
      "Oil         6191 non-null int64\n",
      "nwstate     6191 non-null int64\n",
      "instab      6191 non-null float64\n",
      "polity2l    6191 non-null float64\n",
      "ethfrac     6191 non-null float64\n",
      "relfrac     6191 non-null float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 628.8 KB\n"
     ]
    }
   ],
   "source": [
    "# First, I subset the data to just thos variables we need.\n",
    "# Then I drop all rows with NA values.\n",
    "all_variables = [\"onset\",\"warl\",\"gdpenl\",\"lpop\",\"lmtnest\",\"ncontig\",\"Oil\",\"nwstate\",\"instab\",\"polity2l\",\"ethfrac\",\"relfrac\"]\n",
    "data = data[all_variables].dropna()\n",
    "data = data[data.onset != 4]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make two new dataframes. One called `X_matrix` with only the `x_variables` and one called `Y_matrix` with only the `y_variables`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********X_matrix***********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6191 entries, 0 to 6608\n",
      "Data columns (total 11 columns):\n",
      "warl        6191 non-null int64\n",
      "gdpenl      6191 non-null float64\n",
      "lpop        6191 non-null float64\n",
      "lmtnest     6191 non-null float64\n",
      "ncontig     6191 non-null int64\n",
      "Oil         6191 non-null int64\n",
      "nwstate     6191 non-null int64\n",
      "instab      6191 non-null float64\n",
      "polity2l    6191 non-null float64\n",
      "ethfrac     6191 non-null float64\n",
      "relfrac     6191 non-null float64\n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 580.4 KB\n",
      "None\n",
      "***********Y_matrix***********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6191 entries, 0 to 6608\n",
      "Data columns (total 1 columns):\n",
      "onset    6191 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 96.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_variables = [\"warl\",\"gdpenl\",\"lpop\",\"lmtnest\",\"ncontig\",\"Oil\",\"nwstate\",\"instab\",\"polity2l\",\"ethfrac\",\"relfrac\"]\n",
    "y_variables = \"onset\"\n",
    "X_matrix = pd.DataFrame(data, columns=x_variables)\n",
    "Y_matrix = pd.DataFrame(data, columns=[y_variables])\n",
    "print(\"***********X_matrix***********\")\n",
    "print(X_matrix.info())\n",
    "print(\"***********Y_matrix***********\")\n",
    "print(Y_matrix.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Use scikit learn's `model_selection.train_test_split` function to create a training set (called `train_X` and `train_Y`) and a hold-out set (called `holdout_X` and `holdout_Y`). You can find the documentation for this function here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Both the test set and the training set should be one half of the overall data. Set the random state for your split as `1234`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, holdout_X, train_Y, holdout_Y = train_test_split(X_matrix, np.array(Y_matrix.iloc[:,0]), test_size=0.50, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Now, let's split the holdout data in half to produce `test_X`, `test_Y`, `valid_X`, and `valid_Y`. Use the same random state as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, valid_X, test_Y, valid_Y = train_test_split(holdout_X, holdout_Y, test_size=0.50, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Let's see if we can (relatively closely) replicate the model from Fearon & Laitin. They used logistic regression. Let's start by using _all_ of our data (training, test, and validation) combined to replicate their exact Model 1 from Table 1 (p. 84). \n",
    "\n",
    "Use sckit learn's `LogisticRegression` function with the following parameters:\n",
    "\n",
    "* `penalty = \"none\"`\n",
    "* `random_state=0`\n",
    "* `max_iter=1000`\n",
    "* `class_weight=\"balanced\"`\n",
    "\n",
    "Name your model `logit_all`. You can then use the `.fit(X_matrix, Y_matrix)` method to estimate the model.\n",
    "\n",
    "Once you have an estimated model, use `print(logit_all.coef_)` to print the estimated coefficients. They should closely (but not exactly) match the results in model 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.79053105 -0.33159313  0.227191    0.24723309  0.11802521  0.75136804\n",
      "   1.57614109  0.60841823  0.01840325  0.35136008  0.22816365]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_all = LogisticRegression(penalty=\"none\",random_state=0,max_iter=1000,class_weight=\"balanced\", solver=\"newton-cg\").fit(X_matrix, np.array(Y_matrix.iloc[:,0]))\n",
    "print(logit_all.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Let's see how well the model predicts civil war onset in-sample. Remember, we haven't held any data out for model evaluation. We trained on the same data that we're evaluating with. \n",
    "\n",
    "Start by making a new variable called `logit_all_pred` that represents your class predictions for each example in `X_matrix`. You can use the `logit_all.predict(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_all_pred = logit_all.predict(X_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use scikit learn's `classification_report()` function to evaluate how well the model predicts civil war onset. Use the `print()` function to make sure the report prints out nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79      4053\n",
      "           1       0.67      0.03      0.06      2138\n",
      "\n",
      "    accuracy                           0.66      6191\n",
      "   macro avg       0.67      0.51      0.43      6191\n",
      "weighted avg       0.66      0.66      0.54      6191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(logit_all_pred,np.array(Y_matrix.iloc[:,0])))\n",
    "print(classification_report(logit_all_pred,Y_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, follow along with the example given in block 16 of https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html to create a confusion matrix to visually represent predictive performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#y = Y_matrix.iloc[:,0]\n",
    "y = Y_matrix\n",
    "mat = confusion_matrix(y, logit_all_pred)\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(mat.T, square=True, annot=True,fmt='d',  cbar=False, ax=ax)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.xlim(-0.5, len(np.unique(y))+0.5)\n",
    "plt.ylim(len(np.unique(y))+0.5, -0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Let's repeat the above process the right way. Make a new logit model called `logit_model` using just the `train_X` and `train_Y`. Keep all other hyperparameters the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression(penalty=\"none\",random_state=0,max_iter=1000,class_weight=\"balanced\", solver=\"newton-cg\").fit(train_X, np.array(train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create predictions for your new model, called `logit_pred`, using the `valid_X` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = logit_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the classification report for `logit_pred` compared to the true values, `valid_Y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80      1032\n",
      "           1       0.65      0.03      0.06       516\n",
      "\n",
      "    accuracy                           0.67      1548\n",
      "   macro avg       0.66      0.51      0.43      1548\n",
      "weighted avg       0.67      0.67      0.55      1548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(logit_pred,valid_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "As you can see, the Fearon & Laitin model doesn't do a particularly great job predicting civil war onsets. If we've done everything right, the classification accuracy should be around 67%. That's not horrible, but the false positive rate is very high.\n",
    "\n",
    "Let's now try to model this using a random forest classifier. We will use the `RandomForestClassifier` function from scikit learn. Make a new object called `rf_model` with the following hyperparemeters:\n",
    "\n",
    "* `n_estimators=100`\n",
    "* `max_depth=3`\n",
    "* `random_state=1234`\n",
    "\n",
    "Then, fit your model to `train_X` and `train_Y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=1234,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=1000, max_depth=3,random_state=1234)\n",
    "rf_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "We can check out which features contribute most to our predictive power. Use the `.feature_importances_` attribute to print the weights assigned to each feature. These should sum to 1, meaning they are proportions. If you want, you `zip(...)` them with `x_variables` so it is easy to see which variable is associated with which feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of feature_importances_: 0.9999999999999999 \n",
      "\n",
      "('warl', 0.0322428459598)\n",
      "('gdpenl', 0.20936159847803074)\n",
      "('lpop', 0.2828006470547031)\n",
      "('lmtnest', 0.10117348113401987)\n",
      "('ncontig', 0.021010034279262197)\n",
      "('Oil', 0.02205616333272554)\n",
      "('nwstate', 0.0587352294680228)\n",
      "('instab', 0.04750285174276676)\n",
      "('polity2l', 0.07423580985367105)\n",
      "('ethfrac', 0.06251458764483225)\n",
      "('relfrac', 0.08836675105216567)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of feature_importances_:\", sum(rf_model.feature_importances_), \"\\n\")\n",
    "for val in zip(x_variables, rf_model.feature_importances_):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "Use the `predict` method again to create `rf_pred`, the predictions for the validation set from your random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10\n",
    "\n",
    "Print both the classification report and the confusion matrix for your random forest model using the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1548\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99      1548\n",
      "   macro avg       0.50      0.49      0.50      1548\n",
      "weighted avg       1.00      0.99      0.99      1548\n",
      "\n",
      "(1548, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rf_pred,valid_Y))\n",
    "print(valid_X.shape)\n",
    "len(valid_Y[valid_Y == 1])\n",
    "mat = confusion_matrix(valid_Y, rf_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True,fmt='d',  cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.xlim(-0.5, len(np.unique(valid_Y))+0.5)\n",
    "plt.ylim(len(np.unique(valid_Y))+0.5, -0.5)\n",
    "plt.show()\n",
    "#  Take note of the following waring message:  \n",
    "# \"UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\"\n",
    "# It appears this warning was generated because zero out of 23 1's were predicted correctly:\n",
    "# https://stackoverflow.com/questions/34757653/why-does-scikitlearn-says-f1-score-is-ill-defined-with-fn-bigger-than-0\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "accuracy = balanced_accuracy_score(valid_Y, rf_pred)\n",
    "print(\"Balanced Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/youngjb/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.492 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "0.492 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(train_X, train_Y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance Accuracy Score with Test Data: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = test_Y, clf.predict(test_X)\n",
    "accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "print(\"Balance Accuracy Score with Test Data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11\n",
    "\n",
    "Adjust the model as you feel necessary and evaluate its performance on the validation data. You can choose any evaluation metric you like. Once you are satisfied with your model's performance on the validation data, evaluate its performance on the test data. Report the performance of your model on the test data. If you'd like, you can use scikit learn's `GridSearchCV` or related functions to help you pick a \"best\" model. This is a hard problem. If you can't beat the above model, don't stress. It is really really really hard to predict civil war onsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features=2, random_state=0)\n",
    "regr = ElasticNetCV(cv=5, random_state=0)\n",
    "regr.fit(X, y)\n",
    "\n",
    "#rf_pred_2 = rf_model.predict(test_X)\n",
    "rf_pred_2 = regr.predict(test_X)\n",
    "\n",
    "\n",
    "accuracy = balanced_accuracy_score(test_Y, rf_pred_2)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12\n",
    "\n",
    "Pick a dataset of your choice (from your research or from Googling) and apply a random forest to it. Be prepared to describe the problem that you picked, your modeling choices, and the results of your model. Did it perform better or worse than you expected? Why? What could be done to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
